{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b8673467-382a-4154-9e99-ced576699ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configuração do ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e9bae4da-bfc0-4c72-8248-3594acdf1d7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Import das bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fca7186-cdca-4a05-97bc-3c39f83044aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import subprocess\n",
    "\n",
    "from loguru import logger\n",
    "from pathlib import Path\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5959488d-7bcd-4fa8-830a-6e045ffaefbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Definição dos links e diretórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc3bf60b-6e24-4ef1-bad5-9b2d790fb623",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Mapeia o diretório que está no Bucket S3 com os arquivos do projeto\n",
    "dir_s3_dados = r's3a://databricks-workspace-stack-edf2c-bucket/unity-catalog/3805457818561400/case-tecnico-analise-dados-ifood/dados'\n",
    "dir_s3_dados_brutos = f'{dir_s3_dados}/brutos'\n",
    "dir_s3_dados_processados = f'{dir_s3_dados}/processados'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b089a714-2e29-4996-bb85-298adf3422ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "817c2929-db5c-4ef3-90d3-e9382a162567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f32272e-a0c7-4ca5-b6e3-7525f2f412af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Primeiro é feita uma verificação se o dataset já foi salvo no diretório de dados brutos.\n",
    "Caso o arquivo já esteja lá, não é feito o download novamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "568302b0-b562-4215-b324-24979f9f46f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Pedidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa145e31-f997-4ca5-a08e-3184b65cd33c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificação se os arquivos já estão no diretório de dados brutos\n",
    "if any(f for f in dbutils.fs.ls(dir_s3_dados_processados) if \"pedidos\" in f.path):\n",
    "    logger.info(f'Arquivo processado de pedidos já existe')\n",
    "else:\n",
    "    logger.info('Arquivo processado de pedidos não existe, baixando do diretório de dados brutos')\n",
    "\n",
    "    # Tipos de dados da tabela de pedidos\n",
    "    estrutura_pedidos = StructType([\n",
    "        StructField('cpf', StringType(), True),\n",
    "        StructField('customer_id', StringType(), True),\n",
    "        StructField('customer_name', StringType(), True),\n",
    "\n",
    "        StructField('delivery_address_city', StringType(), True),\n",
    "        StructField('delivery_address_country', StringType(), True),\n",
    "        StructField('delivery_address_district', StringType(), True),\n",
    "        StructField('delivery_address_external_id', StringType(), True),\n",
    "        StructField('delivery_address_latitude', StringType(), True),\n",
    "        StructField('delivery_address_longitude', StringType(), True),\n",
    "        StructField('delivery_address_state', StringType(), True),\n",
    "        StructField('delivery_address_zip_code', StringType(), True),\n",
    "\n",
    "        StructField('items', StringType(), True),\n",
    "\n",
    "        StructField('merchant_id', StringType(), True),\n",
    "        StructField('merchant_latitude', StringType(), True),\n",
    "        StructField('merchant_longitude', StringType(), True),\n",
    "        StructField('merchant_timezone', StringType(), True),\n",
    "\n",
    "        StructField('order_created_at', TimestampType(), True),\n",
    "        StructField('order_id', StringType(), True),\n",
    "        StructField('order_scheduled', BooleanType(), True),\n",
    "        StructField('order_total_amount', DoubleType(), True),\n",
    "        StructField('origin_platform', StringType(), True),\n",
    "        StructField('order_scheduled_date', TimestampType(), True)\n",
    "    ])\n",
    "\n",
    "    # Lê o arquivo do diretório de dados brutos\n",
    "    pedidos = (\n",
    "      spark.read\n",
    "      .schema(estrutura_pedidos)\n",
    "    #   .option(\"multiline\", True)\n",
    "      .json(f\"{dir_s3_dados_brutos}/order.json.gz\")\n",
    "    )\n",
    "    logger.info(f'Foram lidas {pedidos.count()} linhas do arquivo de dados brutos')\n",
    "\n",
    "    # Converte campos de latitude e longitude para flot\n",
    "    pedidos = (\n",
    "        pedidos\n",
    "        .withColumn(\"delivery_address_latitude\", col(\"delivery_address_latitude\").cast(\"double\"))\n",
    "        .withColumn(\"delivery_address_longitude\", col(\"delivery_address_longitude\").cast(\"double\"))\n",
    "        .withColumn(\"merchant_latitude\", col(\"merchant_latitude\").cast(\"double\")) \n",
    "        .withColumn(\"merchant_longitude\", col(\"merchant_longitude\").cast(\"double\"))\n",
    "    )\n",
    "\n",
    "    # Escreve o arquivo .parquet no diretório de dados processados\n",
    "    (\n",
    "        pedidos\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(f'{dir_s3_dados_processados}/pedidos/')\n",
    "    )\n",
    "    logger.success(f'Arquivo processado de pedidos criado com sucesso')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60ebe2aa-7d25-40e9-9dda-d083c2200c3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Usuários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9da1b9f-7c1e-470a-a627-78797f73c57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificação se os arquivos já estão no diretório de dados brutos\n",
    "if any(f for f in dbutils.fs.ls(dir_s3_dados_processados) if \"usuarios\" in f.path):\n",
    "    logger.info(f'Arquivo processado de usuários já existe')\n",
    "else:\n",
    "    logger.info('Arquivo processado de usuários não existe, baixando do diretório de dados brutos')\n",
    "\n",
    "    # Tipos de dados da tabela de usuários\n",
    "    estrutura_usuarios = StructType([\n",
    "        StructField('customer_id', StringType(), True),\n",
    "        StructField('language', StringType(), True),\n",
    "        StructField('created_at', TimestampType(), True),\n",
    "        StructField('active', BooleanType(), True),\n",
    "        StructField('customer_name', StringType(), True),\n",
    "        StructField('customer_phone_area', StringType(), True),\n",
    "        StructField('customer_phone_number', StringType(), True),\n",
    "    ])\n",
    "\n",
    "    # Lê o arquivo do diretório de dados brutos\n",
    "    usuarios = (\n",
    "      spark.read\n",
    "      .option(\"header\", True)\n",
    "      .schema(estrutura_usuarios)\n",
    "      .csv(f\"{dir_s3_dados_brutos}/consumer.csv.gz\")\n",
    "    )\n",
    "    logger.info(f'Foram lidas {usuarios.count()} linhas do arquivo de dados brutos')\n",
    "\n",
    "    # Escreve o arquivo .parquet no diretório de dados processados\n",
    "    (\n",
    "        usuarios\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(f'{dir_s3_dados_processados}/usuarios/')\n",
    "    )\n",
    "\n",
    "    logger.success(f'Arquivo processado de usuários criado com sucesso')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cb5edf5-6bea-495d-ad42-660213be19d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Restaurantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0fce4fd-fb42-4651-b1d6-2b2379a5f0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificação se os arquivos já estão no diretório de dados brutos\n",
    "if any(f for f in dbutils.fs.ls(dir_s3_dados_processados) if \"restaurantes\" in f.path):\n",
    "    logger.info(f'Arquivo processado de restaurantes já existe')\n",
    "else:\n",
    "    logger.info('Arquivo processado de restaurantes não existe, baixando do diretório de dados brutos')\n",
    "\n",
    "    # Tipos de dados da tabela de restaurantes\n",
    "    estrutura_restaurantes = StructType([\n",
    "        StructField('id', StringType(), True),\n",
    "        StructField('created_at', TimestampType(), True),\n",
    "        StructField('enabled', BooleanType(), True),\n",
    "        StructField('price_range', IntegerType(), True),\n",
    "        StructField('average_ticket', DoubleType(), True),\n",
    "        StructField('takeout_time', DoubleType(), True),\n",
    "        StructField('delivery_time', DoubleType(), True),\n",
    "        StructField('minimum_order_value', DoubleType(), True),\n",
    "        StructField('merchant_zip_code', StringType(), True),\n",
    "        StructField('merchant_city', StringType(), True),\n",
    "        StructField('merchant_state', StringType(), True),\n",
    "        StructField('merchant_country', StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # Lê o arquivo do diretório de dados brutos\n",
    "    restaurantes = (\n",
    "      spark.read\n",
    "      .option(\"header\", True)\n",
    "      .schema(estrutura_restaurantes)\n",
    "      .csv(f\"{dir_s3_dados_brutos}/restaurant.csv.gz\")\n",
    "    )\n",
    "    logger.info(f'Foram lidas {restaurantes.count()} linhas do arquivo de dados brutos')\n",
    "\n",
    "    # Escreve o arquivo .parquet no diretório de dados processados\n",
    "    (\n",
    "        restaurantes\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(f'{dir_s3_dados_processados}/restaurantes/')\n",
    "    )\n",
    "\n",
    "    logger.success(f'Arquivo processado de restaurantes criado com sucesso')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10e5908c-4ca2-4c38-863b-c831843e2427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(restaurantes.limit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15575ac3-7462-444e-80d2-5918a54df9c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Usuários teste A/B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd85ff48-ab9b-42ef-a2ed-6529c544b057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Verificação se os arquivos já estão no diretório de dados brutos\n",
    "if any(f for f in dbutils.fs.ls(dir_s3_dados_processados) if \"usuarios_teste_ab\" in f.path):\n",
    "    logger.info(f'Arquivo processado de usuários do teste A/B já existe')\n",
    "else:\n",
    "    logger.info('Arquivo processado de usuários do teste A/B não existe, baixando do diretório de dados brutos')\n",
    "\n",
    "    # Tipos de dados da tabela de usuários do teste A/B\n",
    "    estrutura_usuarios_teste_ab = StructType([\n",
    "        StructField(\"customer_id\", StringType(), True),\n",
    "        StructField(\"is_target\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    # Lê o CSV extraído\n",
    "    usuarios_teste_ab = (\n",
    "        spark.read\n",
    "        .option(\"header\", True)\n",
    "        .schema(estrutura_usuarios_teste_ab)\n",
    "        .csv(f\"{dir_s3_dados_brutos}/ab_test_ref.csv\")\n",
    "    )\n",
    "    logger.info(f'Foram lidas {usuarios_teste_ab.count()} linhas do arquivo de dados brutos')\n",
    "\n",
    "    # Escreve o arquivo .parquet no diretório de dados processados\n",
    "    (\n",
    "        usuarios_teste_ab\n",
    "        .write\n",
    "        .mode(\"overwrite\")\n",
    "        .parquet(f'{dir_s3_dados_processados}/usuarios_teste_ab/')\n",
    "    )\n",
    "\n",
    "    logger.success(f'Arquivo processado de usuários do teste A/B criado com sucesso')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "0-download-arquivos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
